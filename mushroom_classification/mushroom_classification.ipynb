{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e07df0",
   "metadata": {},
   "source": [
    "## Classification of mushrooms, edible or poisonous. Download the mushroom_dataset.csvdataset file from the module content. Load the dataset in your model development framework, examine the features to see they are all nominal features. The first column is the class whichrepresents the mushroom is poisonous or not. Apply necessary pre-processing such as nominal to numerical conversions (e.g. pd.get_dummies). Make sure sanity check the pipeline and perhaps run your favorite baseline classifier first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdd6f8",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecd96836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head:\n",
      "\n",
      "    class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
      "0     p         x           s         n       t    p               f   \n",
      "1     e         x           s         y       t    a               f   \n",
      "2     e         b           s         w       t    l               f   \n",
      "3     p         x           y         w       t    p               f   \n",
      "4     e         x           s         g       f    n               f   \n",
      "\n",
      "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "2            c         b          n  ...                        s   \n",
      "3            c         n          n  ...                        s   \n",
      "4            w         b          k  ...                        s   \n",
      "\n",
      "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring-number ring-type spore-print-color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Datatypes:\n",
      "\n",
      "  class                       object\n",
      "cap-shape                   object\n",
      "cap-surface                 object\n",
      "cap-color                   object\n",
      "bruises                     object\n",
      "odor                        object\n",
      "gill-attachment             object\n",
      "gill-spacing                object\n",
      "gill-size                   object\n",
      "gill-color                  object\n",
      "stalk-shape                 object\n",
      "stalk-root                  object\n",
      "stalk-surface-above-ring    object\n",
      "stalk-surface-below-ring    object\n",
      "stalk-color-above-ring      object\n",
      "stalk-color-below-ring      object\n",
      "veil-type                   object\n",
      "veil-color                  object\n",
      "ring-number                 object\n",
      "ring-type                   object\n",
      "spore-print-color           object\n",
      "population                  object\n",
      "habitat                     object\n",
      "dtype: object\n",
      "\n",
      "Data Description: \n",
      "\n",
      "        class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
      "count   8124      8124        8124      8124    8124  8124            8124   \n",
      "unique     2         6           4        10       2     9               2   \n",
      "top        e         x           y         n       f     n               f   \n",
      "freq    4208      3656        3244      2284    4748  3528            7914   \n",
      "\n",
      "       gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "count          8124      8124       8124  ...                     8124   \n",
      "unique            2         2         12  ...                        4   \n",
      "top               c         b          b  ...                        s   \n",
      "freq           6812      5612       1728  ...                     4936   \n",
      "\n",
      "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "count                    8124                   8124      8124       8124   \n",
      "unique                      9                      9         1          4   \n",
      "top                         w                      w         p          w   \n",
      "freq                     4464                   4384      8124       7924   \n",
      "\n",
      "       ring-number ring-type spore-print-color population habitat  \n",
      "count         8124      8124              8124       8124    8124  \n",
      "unique           3         5                 9          6       7  \n",
      "top              o         p                 w          v       d  \n",
      "freq          7488      3968              2388       4040    3148  \n",
      "\n",
      "[4 rows x 23 columns]\n",
      "Wall time: 56.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "##get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "##get data path and open as a pandas dataframe\n",
    "datapath = cwd + '\\\\data\\\\mushroom_dataset.csv'\n",
    "\n",
    "##get dataframe\n",
    "df = pd.read_csv(datapath)\n",
    "\n",
    "##check contents, dtypes, and description:\n",
    "print('\\nHead:\\n\\n ', df.head())\n",
    "print('\\nDatatypes:\\n\\n ', df.dtypes)\n",
    "print('\\nData Description: \\n\\n', df.describe())\n",
    "\n",
    "##drop rows that have a question mark\n",
    "df = df[df['stalk-root'] != \"?\"]\n",
    "\n",
    "##seperate the class labels from dataframe then drop\n",
    "y = df['class'].values\n",
    "\n",
    "##drop the two features mentioned in the previous cell and class\n",
    "df.drop(['veil-type', 'class'], axis=1, inplace=True)\n",
    "\n",
    "##store the current feature names for later use\n",
    "features = list(df)\n",
    "feature_count = len(features)\n",
    "\n",
    "##encode the data\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "X = np.array(df.values)\n",
    "X = X.flatten()\n",
    "label_encoder.fit(X)\n",
    "X_encoded = label_encoder.transform(X)\n",
    "y_encoded = label_encoder.transform(y)\n",
    "X_encoded = X_encoded.reshape(len(features), -1).T\n",
    "\n",
    "##normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer = Normalizer().fit(X_encoded)\n",
    "X_norm = transformer.transform(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de3ced",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "- The dataset contains twenty-two features.\n",
    "- The data is nominal and will need to be encoded.\n",
    "- The independent variable is 'class', and it contains two unique classes.\n",
    "- Class is contained within the dataframe so will need to be added to own variable and dropped from the set.\n",
    "- The dataset has 8124 samples.\n",
    "- Veil-type has only one value, so this feature can be dropped.\n",
    "- 2400 of '?' appear in 'stalk-root', which is alot but since there are about 8000 samples, these rows are dropped. I know from trial and error that deleting this row will hurt classifier performance, and that is the reason that the entire row was not dropped.\n",
    "- I know from trial and error through this assignment that this exercise is resource intensive and takes a long time to train the models, therfore, to further reduce the dataset, by twenty-five percent, the data was further split into a train set and a test set. This was shown to have no little to no effect on the random trees classifier. Furthermore, the test set can be used as a development set for further testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6dcfce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random forest mean-average accuracy:  0.665  Std:  0.023\n",
      "Wall time: 7.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''run through favorite classifier to get an idea of performance'''\n",
    "\n",
    "##split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "# ##normalize the data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "##Kfold function\n",
    "def kfold_eval(_clf: object, X: np.array, y: np.array) -> np.array:\n",
    "    '''\n",
    "    Desc: K-fold train and validation\n",
    "    \n",
    "    :params _clf: Classifier to use for ensemble training\n",
    "    :params _X: Train dataset\n",
    "    :params _y: Train target\n",
    "    '''\n",
    "    ## accuracy bookkeeping\n",
    "    acc = []\n",
    "    ## stratified split\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    ##iterate through train and test sets\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        _clf.fit(X[train_index], y[train_index])\n",
    "        y_pred = _clf.predict(X[test_index])\n",
    "        acc += [accuracy_score(y[test_index], y_pred)]\n",
    "    return np.array(acc)\n",
    "\n",
    "##Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "acc = kfold_eval(rf_clf, X_train, y_train)\n",
    "print('\\nRandom forest mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98be6e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6572.4', 'cap-shape'),\n",
       " ('6560.4', 'cap-color'),\n",
       " ('6484.7', 'cap-surface'),\n",
       " ('6370.3', 'bruises'),\n",
       " ('6188.1', 'stalk-root'),\n",
       " ('6178.2', 'gill-color'),\n",
       " ('6146.5', 'gill-size'),\n",
       " ('6134.0', 'gill-spacing'),\n",
       " ('6125.9', 'gill-attachment')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('5462.3', 'stalk-color-below-ring'),\n",
       " ('5395.8', 'spore-print-color'),\n",
       " ('4979.4', 'veil-color'),\n",
       " ('4953.7', 'ring-type'),\n",
       " ('4898.6', 'ring-number')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''\n",
    "The decision tree classifier did not perform well so should drop least correlated features from the \n",
    "dataset. Here, the dataset features are directly correlated with the target. The last five \n",
    "features are displayed, which indicates the lowest scoring correlation, as is done in \n",
    "module06_ensemble_notebook.html. Features are dropped and the random forest classifier is again\n",
    "used to test dropped feature influence on the model.\n",
    "'''\n",
    "##Address poor score by removing lowest correlated data\n",
    "##Direct correlation between each column of X and the target y\n",
    "corrs = np.array([np.correlate(X_train[:,j], y_train)[0] for j in range(X_train.shape[1])])\n",
    "\n",
    "##Reverse sort, numpy array negation reverses the order\n",
    "ranks = np.argsort((-corrs))\n",
    "\n",
    "##Display top-9 and bot-5\n",
    "rankings = [(f'{corrs[j]:.1f}', df.columns[j]) for j in ranks]\n",
    "display(rankings[:9])\n",
    "display(rankings[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a39cd4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of samples:  4233\n",
      "Number of Features:  20\n",
      "\n",
      "Random forest mean-average accuracy:  0.657  Std:  0.061\n",
      "Wall time: 9.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "##drop the two features mentioned in the previous cell and class\n",
    "df.drop(['ring-number'], axis=1, inplace=True)\n",
    "\n",
    "##store the current feature names for later use\n",
    "features = list(df)\n",
    "feature_count = len(features)\n",
    "\n",
    "##encode the data\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "X = np.array(df.values)\n",
    "X = X.flatten()\n",
    "label_encoder.fit(X)\n",
    "X_encoded = label_encoder.transform(X)\n",
    "y_encoded = label_encoder.transform(y)\n",
    "X_encoded = X_encoded.reshape(len(features), -1).T\n",
    "\n",
    "##normalize\n",
    "transformer = Normalizer().fit(X_encoded)\n",
    "X_norm = transformer.transform(X_encoded)\n",
    "      \n",
    "##split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "print('\\nNumber of samples: ', len(y_train))\n",
    "print('Number of Features: ', feature_count)\n",
    "\n",
    "##Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "acc = kfold_eval(rf_clf, X_norm, y_encoded)\n",
    "print('\\nRandom forest mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a00c9e",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- Removing the least correlated row slightly improves both model accuracy and generalizeability.\n",
    "- I tried this same approach with up to five of the least correlated features, but each time seemed to worsen performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949937f8",
   "metadata": {},
   "source": [
    "## Report 10-fold CV performances of GaussianNB, linear SVC (useSVC(kernel='linear', probability=True)), MLPClassifier, and DecisionTreeClassifier with default parameters. Now report the RandomForestClassifier performance too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2aa4a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features:  ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-color', 'ring-type', 'spore-print-color', 'population', 'habitat', 'class']\n",
      "\n",
      "Naive Bayes mean-average accuracy:  0.61  Std:  0.006\n",
      "\n",
      "Support Vector Classifier mean-average accuracy:  0.614  Std:  0.001\n",
      "\n",
      "MLP mean-average accuracy:  0.641  Std:  0.021\n",
      "\n",
      "Decision Tree mean-average accuracy:  0.593  Std:  0.024\n",
      "\n",
      "Random forest mean-average accuracy:  0.662  Std:  0.015\n",
      "Wall time: 37.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## import scikit learn classifier base classes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "##imports for multilayer perceptron\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "##convert encoded numpy array as a separate dataframe for further exploration\n",
    "explore_df = pd.DataFrame(X_train, columns=features)\n",
    "explore_df['class'] = y_train\n",
    "print('\\nFeatures: ', list(explore_df))\n",
    "\n",
    "##create dictionary to hold classifier average performance\n",
    "clf_performances = {'Model': [], 'Mean_Acc': [], 'Std': []}\n",
    "\n",
    "##Naive Bayes\n",
    "gb_clf = GaussianNB()\n",
    "acc = kfold_eval(gb_clf, X_train, y_train)\n",
    "##append to performance dict\n",
    "clf_performances['Model'].append('NB')\n",
    "clf_performances['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "clf_performances['Std'].append( np.round(np.std(acc), 3))\n",
    "print('\\nNaive Bayes mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))\n",
    "\n",
    "##Support Vector Classifier\n",
    "svc_clf = SVC(kernel='linear', probability=True)\n",
    "acc = kfold_eval(svc_clf, X_train, y_train)\n",
    "##append to performance dict\n",
    "clf_performances['Model'].append('SVC')\n",
    "clf_performances['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "clf_performances['Std'].append( np.round(np.std(acc), 3))\n",
    "print('\\nSupport Vector Classifier mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))\n",
    "\n",
    "##Multilayer Percptron \n",
    "hid_layers = 3\n",
    "mlp_clf = MLPClassifier() \n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    acc = kfold_eval(mlp_clf, X_train, y_train)\n",
    "##append to performance dict\n",
    "clf_performances['Model'].append('MLP')\n",
    "clf_performances['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "clf_performances['Std'].append( np.round(np.std(acc), 3))\n",
    "print('\\nMLP mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))\n",
    "\n",
    "##Decision Tree\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "acc = kfold_eval(dt_clf, X_train, y_train)\n",
    "##append to performance dict\n",
    "clf_performances['Model'].append('Decision Tree')\n",
    "clf_performances['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "clf_performances['Std'].append(np.round(np.std(acc), 3))\n",
    "print('\\nDecision Tree mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))\n",
    "\n",
    "##Random Forest\n",
    "rf_clf = RandomForestClassifier()\n",
    "acc = kfold_eval(rf_clf, X_train, y_train)\n",
    "##append to performance dict\n",
    "clf_performances['Model'].append('Rand_Forest')\n",
    "clf_performances['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "clf_performances['Std'].append( np.round(np.std(acc), 3))\n",
    "print('\\nRandom forest mean-average accuracy: ', np.round(np.mean(acc), 3), \n",
    "      ' Std: ', np.round(np.std(acc), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837aaca",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "The classifiers all scored somewhat low on performance. I think the reason for that has to do with the way that I chose to encode the data. I chose a method of directly encoding the data as opposed to one-hot-encoding. The direct method can be found in scikit learn's page:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992386a5",
   "metadata": {},
   "source": [
    "## Generate an ensemble of 100 classifiers for each of the four classifiers in Q1. stored as a list. Set the neural network hidden sizes to (3, 3), max iterations to 30, and tolerance to 1e-1. Set the decision tree parameters to max depth of 5 and max features of 5. We will evaluate these four ensemble classifiers.For each of the ensemble, report the first classifier performance in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "feb4c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define Base Classes for each of the classifiers prior to placing in list. This was done to avoid\n",
    "editing any of the classifiers after instantiation and thereby enabling classifiers to be added to a \n",
    "list of preconfigured classifiers.\n",
    "'''\n",
    "\n",
    "class GaussNaiveBayesClf(GaussianNB):\n",
    "    '''\n",
    "    Description: Extends Naive Bayes Base Class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description: Initialize parameters\n",
    "        \n",
    "        :params keyword: Name of classifier\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.keyword = 'GaussNaiveBayesClf'\n",
    "        \n",
    "class SupportVectorClf(SVC):\n",
    "    '''\n",
    "    Description: Extends Support Vector Classifier Base Class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description: Initialize parameters\n",
    "        \n",
    "        :params keyword: Name of classifier\n",
    "        :params kernal: Kernel method to use\n",
    "        :params probability: Enable probability estimates\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.keyword = 'SupportVectorClf'\n",
    "        self.kernel = 'linear'\n",
    "        self.probability = True\n",
    "        \n",
    "class MultiLayerPerceptronClf(MLPClassifier):\n",
    "    '''\n",
    "    Description: Extends Multilayer Perceptron Base Class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description: Initialize parameters\n",
    "        \n",
    "        :params keyword: Name of classifier\n",
    "        :params tol: Train loss threshold only enabled when using SGD\n",
    "        :params max_iter: Max Iterations to Train\n",
    "        :param solver: Weight Optimizer\n",
    "        :param hid_layer: Number of layers between input and output layers\n",
    "        :params hidden_layer_size: Number of Neurons in the ith hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.keyword = 'MultiLayerPerceptonClf'\n",
    "        self.tol=1e-1\n",
    "        self.max_iter = 30\n",
    "        self.solver = 'sgd'\n",
    "        self.hid_layers = 5\n",
    "        self.hidden_layer_sizes = (self.hid_layers,)\n",
    "        \n",
    "class DecisionTreeClf(DecisionTreeClassifier):\n",
    "    '''\n",
    "    Description: Extends Extends Decision Tree Classifier Base Class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description: Initialize parameters\n",
    "        \n",
    "        :params keyword: Name of classifier\n",
    "        :params max_depth: Max depth that the decision tree build. If not pure, then will stop.\n",
    "        :params max_features: Number of features to consider during best split calculation\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.keyword = 'DecisionTreeClf'\n",
    "        self.max_depth = 5\n",
    "        self.max_features = 5\n",
    "        \n",
    "class RandForestClf(RandomForestClassifier):\n",
    "    '''\n",
    "    Description: Extends Extends Random Forest Classifier Base Class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description: Initialize parameters\n",
    "        \n",
    "        :params keyword: Name of classifier\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.keyword = 'RandForestClf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28220e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:00<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  GaussNaiveBayesClf\n",
      "total #results= 100\n",
      "First Learner Acc = 0.63\n",
      "Weak learners average Acc = 0.60 ±0.019\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [02:02<03:35, 71.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  SupportVectorClf\n",
      "total #results= 100\n",
      "First Learner Acc = 0.62\n",
      "Weak learners average Acc = 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [02:05<01:21, 40.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "total #results= 100\n",
      "First Learner Acc = 0.62\n",
      "Weak learners average Acc = 0.59 ±0.057\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [02:06<00:24, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  DecisionTreeClf\n",
      "total #results= 100\n",
      "First Learner Acc = 0.64\n",
      "Weak learners average Acc = 0.63 ±0.021\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:35<00:00, 43.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  RandForestClf\n",
      "total #results= 100\n",
      "First Learner Acc = 0.66\n",
      "Weak learners average Acc = 0.63 ±0.031\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from numpy.random import choice\n",
    "\n",
    "##Instantiate classifiers\n",
    "gb_clf = GaussNaiveBayesClf\n",
    "svc_clf = SupportVectorClf\n",
    "mlp_clf = MultiLayerPerceptronClf\n",
    "dt_clf = DecisionTreeClf\n",
    "rf_clf = RandForestClf\n",
    "\n",
    "##add classifiers to list\n",
    "classifiers = [gb_clf, svc_clf, mlp_clf, dt_clf, rf_clf]\n",
    "\n",
    "##Note: weak_fit, weak_predict, featues_randomsubset, and eval_single is based on \n",
    "##module06_ensemble_notebook.html. It has been modified to fit this problem.\n",
    "def weak_fit(_clf, _list_cols, _X, _y):\n",
    "    '''Builds a single weak learner classifier and subset of features'''\n",
    "    Xs = _X[:,_list_cols]\n",
    "    return _clf().fit(Xs, _y)  # return a single NaiveBayes\n",
    "\n",
    "def weak_predict(_clf, _list_cols, _X):\n",
    "    '''Predicts using a single weak learner classifier'''\n",
    "    Xs = _X[:,_list_cols]\n",
    "    return _clf.predict(Xs), _clf.predict_proba(Xs)\n",
    "\n",
    "def features_randomsubset(_M, _m, n_estimators=100):\n",
    "    '''Returns a list of list of column choices - subset features'''\n",
    "    return [choice(_M, _m, replace=True) for _ in range(n_estimators)]\n",
    "\n",
    "def eval_singleweak(_clf, _X, _y, _niters, _nfeatures):\n",
    "    '''Evaluates a single weak trained model'''\n",
    "    acc = []\n",
    "    for j in range(_niters):\n",
    "        ##Keep the subset features (i.e. columns) the same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, n_estimators=1)\n",
    "        ##10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            clf = weak_fit(_clf ,cols[0], _X[train_index], _y[train_index])\n",
    "            y_pred, y_prob = weak_predict(clf, cols[0], _X[test_index])\n",
    "            acc += [accuracy_score(_y[test_index], y_pred)]\n",
    "    return np.array(acc)\n",
    "\n",
    "##loop through classifiers and retrieve weak learner performance\n",
    "n_iterations = 10\n",
    "for classifier in tqdm(classifiers):\n",
    "    ##weak learner performance\n",
    "    acc = eval_singleweak(classifier, X_train, y_train, n_iterations, len(list(explore_df)))\n",
    "    \n",
    "    ##Summary\n",
    "    print('Classifier Name: ', classifier().keyword)\n",
    "    print(f'total #results= {len(acc)}')\n",
    "    print(f'First Learner Acc = {acc[0]:.2f}')\n",
    "    print(f'Weak learners average Acc = {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "    print('\\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aca579",
   "metadata": {},
   "source": [
    "## Write a function ensemble_fit() to receive the ensemble (i.e. one of the lists in Q2.) and train on one of the subsets of the training data (e.g. random.sample can generate a subset). So each classifier will see only a different subset of the training dataset, also called as subsampling the input data for training. (Use all features in the subsample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f9049d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "def get_feat_subset(_list_cols: list, _X: np.array, _y: np.array) -> tuple:\n",
    "    '''\n",
    "    Gets subset of features\n",
    "    \n",
    "    :params _list_cols: List of dataset column names\n",
    "    :params _X: Train dataset\n",
    "    :params _y: Train target\n",
    "    '''\n",
    "    Xs = _X[:,_list_cols]\n",
    "    return (Xs, _y)\n",
    "\n",
    "##Note: Based on module06_ensemble_notebook.html but modified to fit this problem\n",
    "def ensemble_fit(_clf: object, _ensemble_cols: np.array, _X: np.array, _y: np.array, \n",
    "                 bag_ratio: float) -> object:\n",
    "    '''\n",
    "    Generate numererous trained classifiers as weak learners\n",
    "    \n",
    "    :params _clf: Classifier to use for ensemble training\n",
    "    :params ensemble_cols: split data for ensemble to train on\n",
    "    :params _X: Train dataset\n",
    "    :params _y: Train target\n",
    "    :params bag_ratio: Subsample dataset ratio for each learner\n",
    "    '''\n",
    "    # the list of ensemble columns have a column list for every member of the ensemble\n",
    "    n_estimators = len(_ensemble_cols)\n",
    "    # list of weak learners\n",
    "    ensemble_clf = []\n",
    "    for j in range(n_estimators):\n",
    "        Xs, y = get_feat_subset(_ensemble_cols[j], _X, _y)\n",
    "        b_clf = BaggingClassifier(_clf(), max_samples=bag_ratio)\n",
    "        ensemble_clf += [b_clf.fit(Xs, y)]\n",
    "    return ensemble_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db53f7",
   "metadata": {},
   "source": [
    "## Write a function ensemble_predict() to receive the trained ensemble (i.e. one of the lists in Q3.) and test on the input. Use a voting scheme such as a histogram on the returned predictions by c.predict() by each of the weak classifier. The final prediction should be the np.argmax() of those counts. (Note that c.predict_proba() should have better results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "481208bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##Note: Based on module06_ensemble_notebook.html but modified to fit this problem.\n",
    "from collections import defaultdict\n",
    "\n",
    "##modified \n",
    "def ensemble_predict(_ensemble_clf, _ensemble_cols, _Xtest) -> np.array:\n",
    "    \n",
    "    '''\n",
    "    Uses trained ensemble to predict the outcome by majority voting\n",
    "    \n",
    "    :params _ensemble_clf: Ensemble classifier instance\n",
    "    :params _ensemble_cols: Ensamble columns\n",
    "    :params _Xtest: Test Data\n",
    "    '''\n",
    "    n_estimators = len(_ensemble_clf)\n",
    "    \n",
    "    ##Error check\n",
    "    assert n_estimators==len(_ensemble_cols)  \n",
    "    \n",
    "    #weak learner predictions\n",
    "    ypred_e, yprob_e = [], []\n",
    "    for j in range(n_estimators):\n",
    "        res = weak_predict(_ensemble_clf[j], _ensemble_cols[j], _Xtest)\n",
    "        \n",
    "        ##score/probability of the prediction\n",
    "        ypred_e += [res[0]]\n",
    "        yprob_e += [res[1]] \n",
    "        \n",
    "        ##DEBUG\n",
    "        #print('prediction: ', res[0])\n",
    "        \n",
    "    ##majority voting for each data point in _Xtest\n",
    "    ypred = []\n",
    "    for i in range(_Xtest.shape[0]):\n",
    "        ypred_scores = defaultdict(float)\n",
    "        for j in range(n_estimators):\n",
    "            for c, p in enumerate(yprob_e[j][i]):\n",
    "                ypred_scores[c] += p\n",
    "        ix = max(ypred_scores.items(), key=lambda a: a[1])\n",
    "        ypred += [ix[0]]\n",
    "    \n",
    "    ##convert to numpy and replace zeros by 4 and ones thirteen\n",
    "    ypred = np.array(ypred)\n",
    "    ypred =np.where(ypred == 0, 4, 13)\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96131cbe",
   "metadata": {},
   "source": [
    "## Report 10-fold CV performances of the ensembles with a subsample ratio of 0.1.Compare to a regular decision tree (same subsample ratio). Now repeat these for subsample of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c7685e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.53 ±0.198\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [12:19<12:19, 739.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.59 ±0.008\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.025\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [56:54<00:00, 1707.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.003\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Wall time: 56min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##Note: Based on module06_ensemble_notebook.html but modified to fit this problem.\n",
    "def eval_ensemble(_clf: object, _X: np.array, _y: np.array, _niter: int, \n",
    "                  _n_estimators: int, _nfeatures: int, bag_ratio: float) -> np.array:\n",
    "    \n",
    "    '''\n",
    "    Desc: 10-fold CV using ensemble_fit, ensemble_predict\n",
    "    \n",
    "    :params _clf: Classifier to use for ensemble training\n",
    "    :params _X: Train dataset\n",
    "    :params _y: Train target\n",
    "    :params _niter: Number of iterations to train\n",
    "    :params _n_estimators: Number of weak learners\n",
    "    :params _nfeatures: Number of features per learner\n",
    "    :params bag_ratio: Subsample dataset ratio for each learner\n",
    "    '''\n",
    "    acc = []\n",
    "    for i in range(_niter):\n",
    "        ##Keep subset features, columns same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, n_estimators=_n_estimators)\n",
    "        ##10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            e_clf = ensemble_fit(_clf, cols, _X[train_index], _y[train_index], bag_ratio)\n",
    "            y_pred = ensemble_predict(e_clf, cols, _X[test_index])\n",
    "            acc += [accuracy_score(_y[test_index], y_pred)]\n",
    "    return np.array(acc)\n",
    "\n",
    "##Instantiate classifiers\n",
    "e_gb_clf = GaussNaiveBayesClf\n",
    "e_svc_clf = SupportVectorClf\n",
    "e_mlp_clf = MultiLayerPerceptronClf\n",
    "e_dt_clf = DecisionTreeClf\n",
    "\n",
    "e_classifiers = [e_gb_clf, e_svc_clf, e_mlp_clf, e_dt_clf]\n",
    "\n",
    "##hyperparameters\n",
    "n_iterations = 10\n",
    "n_estimators = 100\n",
    "n_features = feature_count\n",
    "bag_ratios = [0.01, 0.1]\n",
    "\n",
    "e_clf_perf = {'Model': [], 'Mean_Acc': [], 'Std': [], 'Bag_Ratio':[]}\n",
    "##Measure ensemble weak learners performance\n",
    "for bag_ratio in tqdm(bag_ratios):\n",
    "    for classifier in e_classifiers:\n",
    "        acc = eval_ensemble(classifier, X_train, y_train, n_iterations, n_estimators, n_features, bag_ratio)\n",
    "        print('Classifier Name: ', classifier().keyword)\n",
    "        print('Subsample Ratio: ', bag_ratio)\n",
    "        print(f'total #results= {len(acc)}')\n",
    "        print(f'Ensemble learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "        print('\\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "621f0089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The subsample ratio of anything less than 0.01 give an error that \"zero weights cannot be normalized.\" \\nFor that reason, I had to increase the subsample ratio to 0.01 instead of 0.001'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The subsample ratio of anything less than 0.01 gives an error that \"zero weights cannot be normalized.\" \n",
    "For that reason, I had to increase the subsample ratio to 0.01 instead of 0.001'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c8de3",
   "metadata": {},
   "source": [
    "## Report and plot 10-fold CV performances of the ensembles for the training subsample ratios of (0.0005, 0.001, 0.005, 0.01, 0.03, 0.05, 0.1) on the same graph.Add the regular classifiers to the plot with same subsample ratios. (Hint: pass the regular classifier to the same ensemble CV in a list of one element. Same script can be used for this entire step)Report your detailed observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24a1aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.002\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.50 ±0.212\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 1/4 [12:43<38:10, 763.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.60 ±0.008\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.51 ±0.209\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [29:38<30:22, 911.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.002\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.60 ±0.007\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.47 ±0.241\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 3/4 [52:22<18:38, 1118.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.003\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.59 ±0.010\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.061\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [1:37:11<00:00, 1457.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Ensamble Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 100\n",
      "Ensemble learners average Acc= 0.61 ±0.003\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Instantiate classifiers\n",
    "e_gb_clf = GaussNaiveBayesClf\n",
    "e_svc_clf = SupportVectorClf\n",
    "e_mlp_clf = MultiLayerPerceptronClf\n",
    "e_dt_clf = DecisionTreeClf\n",
    "\n",
    "e_classifiers = [e_gb_clf, e_svc_clf, e_mlp_clf, e_dt_clf]\n",
    "\n",
    "##hyperparameters\n",
    "n_iterations = 10\n",
    "n_estimators = 100\n",
    "n_features = len(list(explore_df))\n",
    "\n",
    "'''\n",
    "Note: The bag ratios used were all greater than 0.01 because of the zero division error encountered\n",
    "I think that this has to do with scikit learn's bagging method but I would need to spend more time\n",
    "on that to be certain.\n",
    "'''\n",
    "\n",
    "bag_ratios = [0.01, 0.03, 0.05, 0.1]\n",
    "\n",
    "e_clf_perf = {'Model': [], 'Mean_Acc': [], 'Std': [], 'Bag_Ratio':[]}\n",
    "##Measure ensemble weak learners performance\n",
    "for bag_ratio in tqdm(bag_ratios):\n",
    "    for classifier in e_classifiers:\n",
    "    \n",
    "        acc = eval_ensemble(classifier, X_train, y_train, n_iterations, n_estimators, n_features, bag_ratio)\n",
    "\n",
    "        ##record accuracy scores\n",
    "        e_classifier = 'Ensamble_' + classifier().keyword\n",
    "        e_clf_perf['Model'].append(e_classifier)\n",
    "        e_clf_perf['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "        e_clf_perf['Std'].append(np.round(np.std(acc), 3))\n",
    "        e_clf_perf['Bag_Ratio'].append(bag_ratio)\n",
    "        \n",
    "        print('\\n- Ensamble Classifier Performance on Subsampled Data -')\n",
    "        print('Classifier Name: ', classifier().keyword)\n",
    "        print('Subsample Ratio: ', bag_ratio)\n",
    "        print(f'total #results= {len(acc)}')\n",
    "        print(f'Ensemble learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "        print('\\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb6d7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.59 ±0.026\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.61 ±0.003\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████                                                               | 1/4 [00:00<00:02,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.52 ±0.112\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.01\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.57 ±0.025\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.59 ±0.023\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:01<00:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.50 ±0.097\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.03\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.59 ±0.017\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.60 ±0.016\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:02<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.58 ±0.065\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.05\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.60 ±0.014\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  GaussNaiveBayesClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.60 ±0.015\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  SupportVectorClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.61 ±0.001\n",
      "\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  MultiLayerPerceptonClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.53 ±0.100\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "- Regular Classifier Performance on Subsampled Data -\n",
      "Classifier Name:  DecisionTreeClf\n",
      "Subsample Ratio:  0.1\n",
      "total #results= 10\n",
      "Ensemble learners average Acc= 0.62 ±0.023\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Wall time: 5.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''Subsampling with same ratios of regular classifiers'''\n",
    "\n",
    "##Kfold function\n",
    "def kfold_eval_bagging(_clf: object, X: np.array, y: np.array, bag_ratio: float) -> np.array:\n",
    "    '''\n",
    "    Desc: K-fold with subsampling\n",
    "    \n",
    "    :params _clf: Classifier to use for ensemble training\n",
    "    :params _X: Train dataset\n",
    "    :params _y: Train target\n",
    "    :params _niter: Number of iterations to train\n",
    "    :params bag_ratio: Subsample dataset ratio for each learner\n",
    "    \n",
    "    '''\n",
    "    ## accuracy bookkeeping\n",
    "    acc = []\n",
    "    ## stratified split\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    ##iterate through train and test sets\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        b_clf = BaggingClassifier(_clf(), max_samples=bag_ratio)\n",
    "        b_clf.fit(X[train_index], y[train_index])\n",
    "        y_pred = b_clf.predict(X[test_index])\n",
    "        acc += [accuracy_score(y[test_index], y_pred)]\n",
    "    return np.array(acc)\n",
    "\n",
    "##Instantiate classifiers\n",
    "gb_clf = GaussNaiveBayesClf\n",
    "svc_clf = SupportVectorClf\n",
    "mlp_clf = MultiLayerPerceptronClf\n",
    "dt_clf = DecisionTreeClf\n",
    "classifiers = [gb_clf, svc_clf, mlp_clf, dt_clf]\n",
    "\n",
    "##hyperparameters\n",
    "n_features = len(list(explore_df))\n",
    "bag_ratios = [0.01, 0.03, 0.05, 0.1]\n",
    "\n",
    "clf_perf = {'Model': [], 'Mean_Acc': [], 'Std': [], 'Bag_Ratio':[]}\n",
    "##Measure ensemble weak learners performance\n",
    "for bag_ratio in tqdm(bag_ratios):\n",
    "    for classifier in classifiers:\n",
    "        acc = kfold_eval_bagging(classifier, X_train, y_train, bag_ratio)\n",
    "\n",
    "        ##record accuracy scores\n",
    "        clf_perf['Model'].append(classifier().keyword)\n",
    "        clf_perf['Mean_Acc'].append(np.round(np.mean(acc), 3))\n",
    "        clf_perf['Std'].append(np.round(np.std(acc), 3))\n",
    "        clf_perf['Bag_Ratio'].append(bag_ratio)\n",
    "        \n",
    "        print('\\n- Regular Classifier Performance on Subsampled Data -')\n",
    "        print('Classifier Name: ', classifier().keyword)\n",
    "        print('Subsample Ratio: ', bag_ratio)\n",
    "        print(f'total #results= {len(acc)}')\n",
    "        print(f'Ensemble learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "        print('\\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff73f904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Model=%{x}<br>Mean_Acc=%{y}<br>Std=%{marker.size}<br>Bag_Ratio=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0.01,
           0.01,
           0.01,
           0.01,
           0.03,
           0.03,
           0.03,
           0.03,
           0.05,
           0.05,
           0.05,
           0.05,
           0.1,
           0.1,
           0.1,
           0.1,
           0.01,
           0.01,
           0.01,
           0.01,
           0.03,
           0.03,
           0.03,
           0.03,
           0.05,
           0.05,
           0.05,
           0.05,
           0.1,
           0.1,
           0.1,
           0.1
          ],
          "coloraxis": "coloraxis",
          "size": [
           0.026,
           0.003,
           0.112,
           0.025,
           0.023,
           0.001,
           0.097,
           0.017,
           0.016,
           0.001,
           0.065,
           0.014,
           0.015,
           0.001,
           0.1,
           0.023,
           0.002,
           0.001,
           0.212,
           0.001,
           0.008,
           0.001,
           0.209,
           0.002,
           0.007,
           0.001,
           0.241,
           0.003,
           0.01,
           0.001,
           0.061,
           0.003
          ],
          "sizemode": "area",
          "sizeref": 2.41e-05,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "GaussNaiveBayesClf",
          "SupportVectorClf",
          "MultiLayerPerceptonClf",
          "DecisionTreeClf",
          "GaussNaiveBayesClf",
          "SupportVectorClf",
          "MultiLayerPerceptonClf",
          "DecisionTreeClf",
          "GaussNaiveBayesClf",
          "SupportVectorClf",
          "MultiLayerPerceptonClf",
          "DecisionTreeClf",
          "GaussNaiveBayesClf",
          "SupportVectorClf",
          "MultiLayerPerceptonClf",
          "DecisionTreeClf",
          "Ensamble_GaussNaiveBayesClf",
          "Ensamble_SupportVectorClf",
          "Ensamble_MultiLayerPerceptonClf",
          "Ensamble_DecisionTreeClf",
          "Ensamble_GaussNaiveBayesClf",
          "Ensamble_SupportVectorClf",
          "Ensamble_MultiLayerPerceptonClf",
          "Ensamble_DecisionTreeClf",
          "Ensamble_GaussNaiveBayesClf",
          "Ensamble_SupportVectorClf",
          "Ensamble_MultiLayerPerceptonClf",
          "Ensamble_DecisionTreeClf",
          "Ensamble_GaussNaiveBayesClf",
          "Ensamble_SupportVectorClf",
          "Ensamble_MultiLayerPerceptonClf",
          "Ensamble_DecisionTreeClf"
         ],
         "xaxis": "x",
         "y": [
          0.587,
          0.613,
          0.523,
          0.571,
          0.593,
          0.614,
          0.499,
          0.591,
          0.599,
          0.614,
          0.58,
          0.603,
          0.596,
          0.614,
          0.533,
          0.621,
          0.614,
          0.614,
          0.5,
          0.614,
          0.601,
          0.614,
          0.508,
          0.612,
          0.596,
          0.614,
          0.468,
          0.61,
          0.589,
          0.614,
          0.608,
          0.61
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Bag_Ratio"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "height": 800,
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Mean_Acc"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"3a279ae1-6ab7-468f-aa09-0c6be9d960a5\" class=\"plotly-graph-div\" style=\"height:800px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a279ae1-6ab7-468f-aa09-0c6be9d960a5\")) {                    Plotly.newPlot(                        \"3a279ae1-6ab7-468f-aa09-0c6be9d960a5\",                        [{\"hovertemplate\":\"Model=%{x}<br>Mean_Acc=%{y}<br>Std=%{marker.size}<br>Bag_Ratio=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.01,0.01,0.01,0.01,0.03,0.03,0.03,0.03,0.05,0.05,0.05,0.05,0.1,0.1,0.1,0.1,0.01,0.01,0.01,0.01,0.03,0.03,0.03,0.03,0.05,0.05,0.05,0.05,0.1,0.1,0.1,0.1],\"coloraxis\":\"coloraxis\",\"size\":[0.026,0.003,0.112,0.025,0.023,0.001,0.097,0.017,0.016,0.001,0.065,0.014,0.015,0.001,0.1,0.023,0.002,0.001,0.212,0.001,0.008,0.001,0.209,0.002,0.007,0.001,0.241,0.003,0.01,0.001,0.061,0.003],\"sizemode\":\"area\",\"sizeref\":2.41e-05,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"GaussNaiveBayesClf\",\"SupportVectorClf\",\"MultiLayerPerceptonClf\",\"DecisionTreeClf\",\"GaussNaiveBayesClf\",\"SupportVectorClf\",\"MultiLayerPerceptonClf\",\"DecisionTreeClf\",\"GaussNaiveBayesClf\",\"SupportVectorClf\",\"MultiLayerPerceptonClf\",\"DecisionTreeClf\",\"GaussNaiveBayesClf\",\"SupportVectorClf\",\"MultiLayerPerceptonClf\",\"DecisionTreeClf\",\"Ensamble_GaussNaiveBayesClf\",\"Ensamble_SupportVectorClf\",\"Ensamble_MultiLayerPerceptonClf\",\"Ensamble_DecisionTreeClf\",\"Ensamble_GaussNaiveBayesClf\",\"Ensamble_SupportVectorClf\",\"Ensamble_MultiLayerPerceptonClf\",\"Ensamble_DecisionTreeClf\",\"Ensamble_GaussNaiveBayesClf\",\"Ensamble_SupportVectorClf\",\"Ensamble_MultiLayerPerceptonClf\",\"Ensamble_DecisionTreeClf\",\"Ensamble_GaussNaiveBayesClf\",\"Ensamble_SupportVectorClf\",\"Ensamble_MultiLayerPerceptonClf\",\"Ensamble_DecisionTreeClf\"],\"xaxis\":\"x\",\"y\":[0.587,0.613,0.523,0.571,0.593,0.614,0.499,0.591,0.599,0.614,0.58,0.603,0.596,0.614,0.533,0.621,0.614,0.614,0.5,0.614,0.601,0.614,0.508,0.612,0.596,0.614,0.468,0.61,0.589,0.614,0.608,0.61],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Model\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Mean_Acc\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Bag_Ratio\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"margin\":{\"t\":60},\"height\":800,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3a279ae1-6ab7-468f-aa09-0c6be9d960a5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_df = pd.DataFrame(clf_perf)\n",
    "e_df = pd.DataFrame(e_clf_perf)\n",
    "results_df = reg_df.append(e_df)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(results_df, x=\"Model\", y=\"Mean_Acc\", \n",
    "                 size=\"Std\", color='Bag_Ratio', \n",
    "                 width=900, height=800, size_max=100, \n",
    "                 color_continuous_scale=px.colors.sequential.Viridis)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3b74c",
   "metadata": {},
   "source": [
    "Plot Explanation:\n",
    "\n",
    "- The interactive plot shows how the mean-accuracy varies given different subsample values (bagging values) for different models. The user can scroll over the datapoints, and a hover window will show all available data about that point, such as model, mean-accuracy, std, and bag_ratio.\n",
    "\n",
    "\n",
    "- The y-axis is the mean-accuracy, and the x-axis is the model.  The color embedding represents the subsample size, and the size represents the model generalizeability (std). The smaller the data pointb - the more generalized the model, and the larger the data point - the less generalized the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63aa5a",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- Naive Bayes benefitted from ensembling performed slightly better in both accuracy and standard deviation. The takeaway is that a naive-bayes model perform better than a regular naive-bayers classifier, and it is also more generalized. \n",
    "\n",
    "\n",
    "-  Support vector machine did not seem to benefit from ensembling, since the accuracy is nearly the same. The standard deviation is slightly less however.\n",
    "\n",
    "\n",
    "- The ensemble MLP scored significantly higher for a bag_ratio of 0.1, but generally performed worse for all other bag_ratios. The standard deviation was significantly higher for the ensemble models. In other words, a bag_ratio of 0.1 seemed to perform better for the ensemble, but the regular MLP generally outperformed the ensemble MLP.\n",
    "\n",
    "\n",
    "- The decision tree greatly improved on the standard deviation and generally performed better when ensembled. I think the decision tree definately shows a great increase in performance and seems to be a good candidate for ensembling methods.\n",
    "\n",
    "\n",
    "- The bagging ratio of 0.1 seemed to be correlated to higher performing models, followed by 0.05.\n",
    "\n",
    "\n",
    "- Training seemed to take longer for higher bagging ratios. \n",
    "\n",
    "\n",
    "- Bagging ratios < 0.01 were had a \"divide by zero - normalization\" error most likely do to having to small of a subsample split for scikit learn's bagging method.\n",
    "\n",
    "\n",
    "- The way that I chose to encode the data may have contributed to the generally low scores, but I will likely go with one-hot-encoding next time.\n",
    "\n",
    "\n",
    "- This was a fun assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
